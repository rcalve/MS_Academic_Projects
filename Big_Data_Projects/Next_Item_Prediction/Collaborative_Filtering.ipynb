{"cells":[{"cell_type":"code","source":["# Importing the necessary libraries \nimport pandas as pd\nfrom pyspark.sql.functions import collect_list, col\nfrom pyspark.sql import SparkSession"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b44b3e92-acf9-4740-bd4b-81d01115617b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/plain":[],"application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"}}],"execution_count":0},{"cell_type":"code","source":["# For reading the files from MongoDB\nmongo_uri = \"mongodb+srv://rmaxseiner:s7wUCv7q7Xkji8P@cluster0.opg6m.mongodb.net\"\ndatabase_name = \"AIT_614\"\ncollection_name = \"orders\"\n\nspark = SparkSession.builder \\\n    .appName(\"MongoDBAtlasConnector\") \\\n    .config(\"spark.mongodb.input.uri\", f\"{mongo_uri}/{database_name}.{collection_name}\") \\\n    .config(\"spark.mongodb.output.uri\", f\"{mongo_uri}/{database_name}.{collection_name}\") \\\n    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n    .getOrCreate()\n\n\ncollection_name = \"order_product\"\n\norder_product_train_df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n    .option(\"uri\", f\"{mongo_uri}/{database_name}.{collection_name}\") \\\n    .option(\"pipeline\", \"[{ $match: { data_set: 'train' } }]\") \\\n    .load()\nprint(\"Then number of records in the \" + collection_name + \" dataframe train set is \" + str(order_product_train_df.count()))\n\nprint(order_product_train_df.describe())\n\norder_product_prior_df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n    .option(\"uri\", f\"{mongo_uri}/{database_name}.{collection_name}\") \\\n    .option(\"pipeline\", \"[{ $match: { data_set: 'prior' } }]\") \\\n    .load()\n\nprint(\"Then number of records in the \" + collection_name + \" dataframe prior set is \" + str(order_product_prior_df.count()))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"89def869-7dda-4826-ace1-7a7eead8f8ab","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Then number of records in the order_product dataframe train set is 1384617\nDataFrame[summary: string, add_to_cart_order: string, data_set: string, order_id: string, product_id: string, reordered: string]\nThen number of records in the order_product dataframe prior set is 32434489\n"]}],"execution_count":0},{"cell_type":"code","source":["# Reading another file from Mongo DB\ncollection_name = \"orders\"\norders_df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n    .option(\"uri\", f\"{mongo_uri}/{database_name}.{collection_name}\") \\\n    .load()\n\nprint(\"Then number of records in the \" + collection_name + \" dataframe is \" + str(orders_df.count()))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2208d9d8-3d57-46bf-8cc8-07bd9d97cdb5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Then number of records in the orders dataframe is 3421083\n"]}],"execution_count":0},{"cell_type":"code","source":["# Selecting only the necessary columns to reduce the load as this is a big dataset\ntemp1 = order_product_prior_df.select('order_id', 'product_id')\ntemp2 = order_product_train_df.select('order_id', 'product_id')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f9bfa45b-5e95-407d-8b56-6bc771241a65","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Merging the above pyspark dataframes\nmerge_temp = temp1.union(temp2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"aaa00cf9-1760-4b67-a9c6-e76dc6aab320","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Displaying the merged dataframe\nmerge_temp.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a4dcc827-6e45-46eb-83b9-fbbd1d747414","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------+----------+\n|order_id|product_id|\n+--------+----------+\n|       2|     33120|\n|       2|     28985|\n|       2|      9327|\n|       2|     45918|\n|       2|     30035|\n+--------+----------+\nonly showing top 5 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# Choosing only the necessary columns from the orders dataframe\nuser_temp = orders_df.select('order_id', 'user_id')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"da2853bc-0a01-40ed-923c-9068dbedaa04","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Merging the orders with the train&prior merged dataframe to get the user_id's for each order\ndf4 = merge_temp.join(user_temp, merge_temp.order_id == user_temp.order_id, 'inner').select(merge_temp[\"*\"], user_temp['user_id'])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a747c139-97d9-4ee1-ad87-f63a94b0514e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Displaying the combined dataframe\ndf4.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"58409097-40a6-4bb2-90d3-a32802917421","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------+----------+-------+\n|order_id|product_id|user_id|\n+--------+----------+-------+\n|      26|     35951| 153404|\n|      26|     24852| 153404|\n|      26|     46206| 153404|\n|      26|     25890| 153404|\n|      26|     33120| 153404|\n+--------+----------+-------+\nonly showing top 5 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# To get the user_id, product_id and the number of times the user has purchased that particular product\ndf5 = df4.groupBy('user_id', 'product_id').count().sort(\"count\" , ascending = False) "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"cfae0cde-b185-415d-9d5e-eacf65fb4df2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df5.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d4d6e2d9-de37-4f42-ae38-da551daca9bf","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+----------+-----+\n|user_id|product_id|count|\n+-------+----------+-----+\n|  41356|      6583|  100|\n|  41356|     14366|  100|\n|  41356|     38652|  100|\n|  17997|      4210|   99|\n| 141736|     25133|   99|\n+-------+----------+-----+\nonly showing top 5 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# Ensuring that the columns are in the right datatype as they have to be in integer format for the ALS model\nfinal_df = df5.withColumn(\"user_id\", df5[\"user_id\"].cast('int')).withColumn(\"prod_id\", df5[\"product_id\"].cast('int')).withColumn(\"prod_count\", df5[\"count\"].cast('int'))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f8ce7d15-0b91-4123-a9e5-df6036f5788d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Checking the datatypes of each column\nfinal_df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"5808f561-4b98-4988-8d74-6d244382bafa","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- user_id: integer (nullable = true)\n |-- product_id: integer (nullable = true)\n |-- count: long (nullable = false)\n |-- prod_id: integer (nullable = true)\n |-- prod_count: integer (nullable = false)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# Removing duplicate columns\nfinal_df = final_df.select('user_id', 'prod_id','prod_count')\nfinal_df.show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"303cebef-e01f-435b-9771-f7544ea7b0ab","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+-------+----------+\n|user_id|prod_id|prod_count|\n+-------+-------+----------+\n|  41356|   6583|       100|\n|  41356|  14366|       100|\n|  41356|  38652|       100|\n|  17997|   4210|        99|\n| 141736|  25133|        99|\n|  41356|  29671|        99|\n| 103593|  28204|        99|\n|  99707|  24852|        98|\n| 120897|  12013|        98|\n|  84478|  31981|        97|\n+-------+-------+----------+\nonly showing top 10 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# Checking for one sample user\ndisplay(final_df.filter(final_df.user_id == 1))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"54f99baf-8246-4ba4-b6d5-bf69b547dcc2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[1,196,11],[1,12427,10],[1,10258,10],[1,25133,9],[1,46149,4],[1,13032,4],[1,26405,3],[1,26088,3],[1,49235,3],[1,38928,2],[1,39657,2],[1,13176,2],[1,30450,1],[1,27845,1],[1,17122,1],[1,41787,1],[1,10326,1],[1,14084,1],[1,35951,1]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"user_id","type":"\"integer\"","metadata":"{}"},{"name":"prod_id","type":"\"integer\"","metadata":"{}"},{"name":"prod_count","type":"\"integer\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_id</th><th>prod_id</th><th>prod_count</th></tr></thead><tbody><tr><td>1</td><td>196</td><td>11</td></tr><tr><td>1</td><td>12427</td><td>10</td></tr><tr><td>1</td><td>10258</td><td>10</td></tr><tr><td>1</td><td>25133</td><td>9</td></tr><tr><td>1</td><td>46149</td><td>4</td></tr><tr><td>1</td><td>13032</td><td>4</td></tr><tr><td>1</td><td>26405</td><td>3</td></tr><tr><td>1</td><td>26088</td><td>3</td></tr><tr><td>1</td><td>49235</td><td>3</td></tr><tr><td>1</td><td>38928</td><td>2</td></tr><tr><td>1</td><td>39657</td><td>2</td></tr><tr><td>1</td><td>13176</td><td>2</td></tr><tr><td>1</td><td>30450</td><td>1</td></tr><tr><td>1</td><td>27845</td><td>1</td></tr><tr><td>1</td><td>17122</td><td>1</td></tr><tr><td>1</td><td>41787</td><td>1</td></tr><tr><td>1</td><td>10326</td><td>1</td></tr><tr><td>1</td><td>14084</td><td>1</td></tr><tr><td>1</td><td>35951</td><td>1</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Running the ALS model for collaborative filtering\nfrom pyspark.ml.recommendation import ALS\n\n# Splitting the dataset into test and train for evalution purposes\ntrain_df, test_df = final_df.randomSplit([0.8, 0.2])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e436d139-e945-4f77-aabf-dfe8a3092082","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Building the ALS model\nals_obj = ALS(maxIter=5, rank=10, regParam=0.1, userCol=\"user_id\", itemCol=\"prod_id\", ratingCol= \"prod_count\", coldStartStrategy=\"drop\", implicitPrefs=False)\n\nals_model = als_obj.fit(train_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1d67878a-1eec-46c1-ba4f-3d87d749f239","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Testing the predictions\npred_res = als_model.transform(test_df)\n\n# Measuring the RMSE ( root mean square error)\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nreg_evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"prod_count\", predictionCol=\"prediction\")\nrmse = reg_evaluator.evaluate(pred_res)\n\nprint(str(rmse))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"3c534833-199a-4c7e-9c29-e7ff7ce80113","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["2.6983857476651947\n"]}],"execution_count":0},{"cell_type":"markdown","source":["It was a real challenge to have the ALS model running. Preprocessing the code took the longest time. We tried running the Cross Validation but it kept shutting down the kernel due the large size of the dataset and the combinations of the parameters to be run for them."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c6777506-f2ad-4ebe-8bbc-72e3948cd530","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Generate top 3 product recommendations for each user ( Top 3 recommendations only - due to the large size of the dataset we chose to have only the top 3 )\nuserRecs = als_model.recommendForAllUsers(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"fb2b2411-337d-4080-801c-eaa4db57503b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Displaying the recommendations for one user \n# This returns the top 3 product_id's and the rating for each of them \nuserRecs.where(userRecs.user_id==1).show(truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"3e619642-b7ff-4311-9cad-1345abdad5af","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+-----------------------------------------------------------+\n|user_id|recommendations                                            |\n+-------+-----------------------------------------------------------+\n|1      |[{19907, 38.025448}, {5997, 35.425365}, {43532, 32.658146}]|\n+-------+-----------------------------------------------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# Generating recommendations for each item ( Top 3 recommendations only - due to the large size of the dataset we chose to have only the top 3 )\nrec_for_prod = als_model.recommendForAllItems(3) "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"9a957742-8f7c-4ddd-9930-7990e3a5ef74","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Displaying the recommendations for one product \n# This gives us the top 3 user_id's and rating for each of them\nrec_for_prod.where(rec_for_prod.prod_id==10).show(truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2cec2d28-94cc-4dc2-889d-735c82ac6ce6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+--------------------------------------------------------+\n|prod_id|recommendations                                         |\n+-------+--------------------------------------------------------+\n|10     |[{16397, 46.7334}, {82414, 33.8878}, {26489, 32.607334}]|\n+-------+--------------------------------------------------------+\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["<h1> References: </h1>\n\n<strong>1. [1] Dr. Liao’s lab tutorials and code examples on blackboard for the AIT614 course </strong>\n<p> 2. Collaborative Filtering - Pyspark - https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html </p>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"29a65698-ff21-434b-bda1-3ea5b2ece2de","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Final_Collab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1977626175573661}},"nbformat":4,"nbformat_minor":0}
