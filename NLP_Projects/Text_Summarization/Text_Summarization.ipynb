{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e73ca49c",
   "metadata": {},
   "source": [
    "# AIT526 Individual Lab 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a98b6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d147ae7b",
   "metadata": {},
   "source": [
    "## Task 1 - Text Summarization with Word Frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8cfb5898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural language processing (nlp) is an interdisciplinary subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.  the goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. the technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\\nchallenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\\nnatural language processing has its roots in the 1950s. already in 1950, alan turing published an article titled \"computing machinery and intelligence\" which proposed what is now called the turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. the proposed test includes a task that involves the automated interpretation and generation of natural language.\\nthe premise of symbolic nlp is well-summarized by john searle\\'s chinese room experiment: given a collection of rules (e.g., a chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other nlp tasks) by applying those rules to the data it confronts.\\nup to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  this was due to both the steady increase in computational power (see moore\\'s law) and the gradual lessening of the dominance of chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[7]\\nin the 2010s, representation learning and deep neural network-style machine learning methods became widespread in natural language processing. that popularity was due partly to a flurry of results showing that such techniques[8][9] can achieve state-of-the-art results in many natural language tasks, e.g., in language modeling[10] and parsing.[11][12] this is increasingly important in medicine and healthcare, where nlp helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care.[13]\\nin the early days, many language-processing systems were designed by symbolic methods, i.e., the hand-coding of a set of rules, coupled with a dictionary lookup:[14][15] such as by writing grammars or devising heuristic rules for stemming.\\nmore recent systems based on machine-learning algorithms have many advantages over hand-produced rules: \\ndespite the popularity of machine learning in nlp research, symbolic methods are still (2020) commonly used:\\nsince the so-called \"statistical revolution\"[16][17] in the late 1980s and mid-1990s, much natural language processing research has relied heavily on machine learning. the machine-learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora (the plural form of corpus, is a set of documents, possibly with human or computer annotations) of typical real-world examples.\\nmany different classes of machine-learning algorithms have been applied to natural-language-processing tasks. these algorithms take as input a large set of \"features\" that are generated from the input data. increasingly, however, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to each input feature (complex-valued embeddings,[18] and neural networks in general have also been proposed, for e.g. speech[19]). such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system.\\nsome of the earliest-used machine learning algorithms, such as decision trees, produced systems of hard if-then rules similar to existing hand-written rules.  however, part-of-speech tagging introduced the use of hidden markov models to natural language processing, and increasingly, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data. the cache language models upon which many speech recognition systems now rely are examples of such statistical models.  such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks.\\nsince the neural turn, statistical methods in nlp research have been largely replaced by neural networks. however, they continue to be relevant for contexts in which statistical interpretability and transparency is required.\\na major drawback of statistical methods is that they require elaborate feature engineering. since 2015,[20] the field has thus largely abandoned statistical methods and shifted to neural networks for machine learning. popular techniques include the use of word embeddings to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task (e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing). in some areas, this shift has entailed substantial changes in how nlp systems are designed, such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing. for instance, the term neural machine translation (nmt) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, obviating the need for intermediate steps such as word alignment and language modeling that was used in statistical machine translation (smt).\\nthe following is a list of some of the most commonly researched tasks in natural language processing. some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\\nthough natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. a coarse division is given below.\\nbased on long-standing trends in the field, it is possible to extrapolate future directions of nlp. as of 2020, three trends among the topics of the long-standing series of conll shared tasks can be observed:[41]\\nmost higher-level nlp applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language. more broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of nlp (see trends among conll shared tasks above).\\ncognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"[42] cognitive science is the interdisciplinary, scientific study of the mind and its processes.[43] cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.[44] especially during the age of symbolic nlp, the area of computational linguistics maintained strong ties with cognitive studies.\\nas an example, george lakoff offers a methodology to build natural language processing (nlp) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,[45] with two defining aspects:\\nties with cognitive linguistics are part of the historical heritage of nlp, but they have been less frequently addressed since the statistical turn during the 1990s. nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,[47] functional grammar,[48] construction grammar,[49] computational psycholinguistics and cognitive neuroscience (e.g., act-r), however, with limited uptake in mainstream nlp (as measured by presence on major conferences[50] of the acl). more recently, ideas of cognitive nlp have been revived as an approach to achieve explainability, e.g., under the notion of \"cognitive ai\".[51] likewise, ideas of cognitive nlp are inherent to neural models multimodal nlp (although rarely made explicit).[52]\\n'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.1 - Web Scraping Technique\n",
    "def get_content_from_page(url):\n",
    "    \n",
    "    final_page_text = \"\"\n",
    "    \n",
    "    page_response = requests.get(url)\n",
    "    soup_response = BeautifulSoup(page_response.content, \"lxml\")\n",
    "    final_content = soup_response.find(id=\"content\")\n",
    "    pars = final_content.find_all(\"p\")\n",
    "    \n",
    "    for p in pars:\n",
    "        final_page_text += p.text\n",
    "        \n",
    "    return final_page_text.lower()\n",
    "\n",
    "URL = 'https://en.wikipedia.org/wiki/Natural_language_processing'\n",
    "content = get_content_from_page(URL)\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "90796370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of sentences are:  50 \n",
      "\n",
      "Total Number of Words:  1520\n",
      "['natural', 'language', 'processing', '(', 'nlp', ')', 'is', 'an', 'interdisciplinary', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', 'concerned'] \n",
      "\n",
      "Total Number of Words:  1594\n",
      "['natural', 'language', 'processing', '(', 'nlp', ')', 'is', 'an', 'interdisciplinary', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', 'concerned'] \n",
      "\n",
      "The no of words after removing punctuation are:  1340\n",
      "The first 20 words are: \n",
      " ['natural', 'language', 'processing', 'nlp', 'is', 'an', 'interdisciplinary', 'subfield', 'of', 'linguistics', 'computer', 'science', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between'] \n",
      "\n",
      "No of words without any stopwords:  862 \n",
      "\n",
      "The first 20 words are: \n",
      " ['natural', 'language', 'processing', 'nlp', 'interdisciplinary', 'subfield', 'linguistics', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'interactions', 'computers', 'human', 'language', 'particular', 'program', 'computers', 'process'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1.2\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "\n",
    "# Tokenization\n",
    "\n",
    "# Sentence Tokenizer\n",
    "my_sentences = sent_tokenize(content)\n",
    "print('The no of sentences are: ', len(my_sentences), '\\n')\n",
    "\n",
    "# Word Tokenizer\n",
    "my_words = word_tokenize(content)\n",
    "print('Total Number of Words: ', len(my_words))\n",
    "print(my_words[:20], '\\n')\n",
    "\n",
    "my_punct_tokenize = wordpunct_tokenize(content)\n",
    "print('Total Number of Words: ', len(my_punct_tokenize))\n",
    "print(my_punct_tokenize[:20], '\\n')\n",
    "\n",
    "\n",
    "# Removing punctuation\n",
    "words_without_punctuation = []\n",
    "\n",
    "words_without_punctuation = [''.join(eachcharac for eachcharac in eachword if eachcharac not in string.punctuation ) for eachword in my_punct_tokenize]\n",
    "\n",
    "final_words_without_punct = [eachw.lower() for eachw in words_without_punctuation if eachw!='']\n",
    "\n",
    "print(\"The no of words after removing punctuation are: \",len(final_words_without_punct))\n",
    "print(\"The first 20 words are: \\n\", final_words_without_punct[:20], '\\n')\n",
    "\n",
    "\n",
    "\n",
    "# Removing stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "without_stop_words = []\n",
    "\n",
    "for i in final_words_without_punct:\n",
    "    if i not in stop_words:\n",
    "        without_stop_words.append(i)\n",
    "    \n",
    "\t\t\n",
    "print('No of words without any stopwords: ', len(without_stop_words), '\\n')\n",
    "print(\"The first 20 words are: \\n\", without_stop_words[:20], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7569360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('language', 1.0), ('natural', 0.7142857142857143), ('nlp', 0.6071428571428571), ('processing', 0.5714285714285714), ('machine', 0.4642857142857143), ('learning', 0.4642857142857143), ('cognitive', 0.4642857142857143), ('statistical', 0.42857142857142855), ('e', 0.35714285714285715), ('tasks', 0.35714285714285715), ('linguistics', 0.32142857142857145), ('rules', 0.32142857142857145), ('g', 0.32142857142857145), ('models', 0.32142857142857145), ('neural', 0.2857142857142857), ('based', 0.25), ('systems', 0.21428571428571427), ('algorithms', 0.21428571428571427), ('methods', 0.21428571428571427), ('many', 0.21428571428571427)]\n"
     ]
    }
   ],
   "source": [
    "# 1.3\n",
    "\n",
    "def calc_word_freq(input_words):\n",
    "    \n",
    "    # to calculate word frequency \n",
    "    word_freq_list = FreqDist(input_words)\n",
    "    \n",
    "    # finding the max freq\n",
    "    maximum_cnt = word_freq_list.most_common(1)[0][1]\n",
    "    \n",
    "    # weighted freqencies\n",
    "    for each_word in word_freq_list.keys():\n",
    "        word_freq_list[each_word] = word_freq_list[each_word] / maximum_cnt\n",
    "    return word_freq_list\n",
    "\n",
    "freq_of_words = calc_word_freq(without_stop_words)\n",
    "print(freq_of_words.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "333cb13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'more recent systems based on machine-learning algorithms have many advantages over hand-produced rules: \\ndespite the popularity of machine learning in nlp research, symbolic methods are still (2020) commonly used:\\nsince the so-called \"statistical revolution\"[16][17] in the late 1980s and mid-1990s, much natural language processing research has relied heavily on machine learning.': 9.607142857142856,\n",
       " 'as an example, george lakoff offers a methodology to build natural language processing (nlp) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,[45] with two defining aspects:\\nties with cognitive linguistics are part of the historical heritage of nlp, but they have been less frequently addressed since the statistical turn during the 1990s.': 7.499999999999997,\n",
       " 'natural language processing (nlp) is an interdisciplinary subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.': 7.357142857142856,\n",
       " 'challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.': 6.357142857142858,\n",
       " \"the premise of symbolic nlp is well-summarized by john searle's chinese room experiment: given a collection of rules (e.g., a chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other nlp tasks) by applying those rules to the data it confronts.\": 6.071428571428571,\n",
       " 'however, part-of-speech tagging introduced the use of hidden markov models to natural language processing, and increasingly, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data.': 5.964285714285713,\n",
       " 'nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,[47] functional grammar,[48] construction grammar,[49] computational psycholinguistics and cognitive neuroscience (e.g., act-r), however, with limited uptake in mainstream nlp (as measured by presence on major conferences[50] of the acl).': 5.607142857142855,\n",
       " 'starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.': 5.5,\n",
       " 'for instance, the term neural machine translation (nmt) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, obviating the need for intermediate steps such as word alignment and language modeling that was used in statistical machine translation (smt).': 5.357142857142858,\n",
       " 'that popularity was due partly to a flurry of results showing that such techniques[8][9] can achieve state-of-the-art results in many natural language tasks, e.g., in language modeling[10] and parsing.': 4.9642857142857135,\n",
       " 'in some areas, this shift has entailed substantial changes in how nlp systems are designed, such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing.': 4.821428571428571,\n",
       " '[7]\\nin the 2010s, representation learning and deep neural network-style machine learning methods became widespread in natural language processing.': 4.571428571428571,\n",
       " '[13]\\nin the early days, many language-processing systems were designed by symbolic methods, i.e., the hand-coding of a set of rules, coupled with a dictionary lookup:[14][15] such as by writing grammars or devising heuristic rules for stemming.': 4.178571428571428,\n",
       " 'increasingly, however, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to each input feature (complex-valued embeddings,[18] and neural networks in general have also been proposed, for e.g.': 4.142857142857143,\n",
       " 'many different classes of machine-learning algorithms have been applied to natural-language-processing tasks.': 4.142857142857142,\n",
       " 'as of 2020, three trends among the topics of the long-standing series of conll shared tasks can be observed:[41]\\nmost higher-level nlp applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language.': 3.9999999999999996,\n",
       " 'popular techniques include the use of word embeddings to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task (e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing).': 3.928571428571429,\n",
       " 'up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.': 3.5000000000000004,\n",
       " 'transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.': 3.3571428571428568,\n",
       " 'the machine-learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora (the plural form of corpus, is a set of documents, possibly with human or computer annotations) of typical real-world examples.': 3.2857142857142856,\n",
       " 'the cache language models upon which many speech recognition systems now rely are examples of such statistical models.': 2.928571428571429,\n",
       " 'though natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience.': 2.892857142857142,\n",
       " 'the following is a list of some of the most commonly researched tasks in natural language processing.': 2.8571428571428568,\n",
       " 'some of the earliest-used machine learning algorithms, such as decision trees, produced systems of hard if-then rules similar to existing hand-written rules.': 2.6428571428571432,\n",
       " '[51] likewise, ideas of cognitive nlp are inherent to neural models multimodal nlp (although rarely made explicit).': 2.642857142857143,\n",
       " 'more recently, ideas of cognitive nlp have been revived as an approach to achieve explainability, e.g., under the notion of \"cognitive ai\".': 2.607142857142857,\n",
       " 'more broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of nlp (see trends among conll shared tasks above).': 2.5000000000000004,\n",
       " 'since the neural turn, statistical methods in nlp research have been largely replaced by neural networks.': 2.464285714285714,\n",
       " 'since 2015,[20] the field has thus largely abandoned statistical methods and shifted to neural networks for machine learning.': 2.428571428571429,\n",
       " 'natural language processing has its roots in the 1950s.': 2.3571428571428568,\n",
       " 'such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks.': 2.214285714285715,\n",
       " 'the proposed test includes a task that involves the automated interpretation and generation of natural language.': 2.1785714285714284,\n",
       " '[44] especially during the age of symbolic nlp, the area of computational linguistics maintained strong ties with cognitive studies.': 2.0,\n",
       " '[43] cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.': 1.9642857142857142,\n",
       " 'the goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them.': 1.6785714285714286,\n",
       " 'some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.': 1.6785714285714286,\n",
       " \"this was due to both the steady increase in computational power (see moore's law) and the gradual lessening of the dominance of chomskyan theories of linguistics (e.g.\": 1.6428571428571428,\n",
       " 'such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system.': 1.5357142857142858,\n",
       " '[11][12] this is increasingly important in medicine and healthcare, where nlp helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care.': 1.5000000000000009,\n",
       " 'already in 1950, alan turing published an article titled \"computing machinery and intelligence\" which proposed what is now called the turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence.': 1.4642857142857142,\n",
       " 'based on long-standing trends in the field, it is possible to extrapolate future directions of nlp.': 1.357142857142857,\n",
       " 'these algorithms take as input a large set of \"features\" that are generated from the input data.': 1.1785714285714284,\n",
       " 'a major drawback of statistical methods is that they require elaborate feature engineering.': 0.9285714285714285,\n",
       " '\"[42] cognitive science is the interdisciplinary, scientific study of the mind and its processes.': 0.8928571428571427,\n",
       " 'however, they continue to be relevant for contexts in which statistical interpretability and transparency is required.': 0.8214285714285713,\n",
       " 'the technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.': 0.6428571428571428,\n",
       " 'cognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.': 0.5714285714285714,\n",
       " 'speech[19]).': 0.2142857142857143,\n",
       " 'a coarse division is given below.': 0.17857142857142855,\n",
       " '[52]': 0.03571428571428571}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.4 \n",
    "import operator\n",
    "sent_freq_dict = {}\n",
    "\n",
    "# calculating the frequency for each sentence based on the individual word frequency\n",
    "for each_sentence in my_sentences:\n",
    "    each_sentence = each_sentence.lower()\n",
    "    word_list = wordpunct_tokenize(each_sentence)\n",
    "    sum = 0\n",
    "    for each_word in word_list:\n",
    "        sum = sum + freq_of_words[each_word]\n",
    "    #print(each_sentence, sum)\n",
    "    sent_freq_dict[each_sentence] = sum\n",
    "    \n",
    "# sorting the dictionary in descending order\n",
    "ranked_sent = dict(sorted(sent_freq_dict.items(), key=operator.itemgetter(1), reverse=True))\n",
    "ranked_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b1094e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary based on sentence count: \n",
      "\n",
      "['more recent systems based on machine-learning algorithms have many advantages over hand-produced rules: \\ndespite the popularity of machine learning in nlp research, symbolic methods are still (2020) commonly used:\\nsince the so-called \"statistical revolution\"[16][17] in the late 1980s and mid-1990s, much natural language processing research has relied heavily on machine learning.', 'as an example, george lakoff offers a methodology to build natural language processing (nlp) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,[45] with two defining aspects:\\nties with cognitive linguistics are part of the historical heritage of nlp, but they have been less frequently addressed since the statistical turn during the 1990s.']\n",
      "\n",
      "\n",
      "Summary based on word count: \n",
      "\n",
      "more recent systems based on machine - learning algorithms have many advantages over hand - produced rules : despite the popularity of machine learning in nlp research , symbolic methods are still ( 2020 ) commonly used : since the so - called \" statistical revolution \"[ 16 ][ 17 ] in the late 1980s and mid - 1990s , much natural language processing research has relied heavily on machine learning .\n",
      "as an example , george lakoff offers a methodology to build natural language processing ( nlp ) algorithms through the perspective of cognitive science , along with the\n",
      "\n",
      "\n",
      "Summary based on Percentage: \n",
      "\n",
      "more recent systems based on machine - learning algorithms have many advantages over hand - produced rules : despite the popularity of machine learning in nlp research , symbolic methods are still ( 2020 ) commonly used : since the so - called \" statistical revolution \"[ 16 ][ 17 ] in the late 1980s and mid - 1990s , much natural language processing research has relied heavily on machine learning .\n",
      "as an example , george lakoff offers a methodology to build natural language processing ( nlp ) algorithms through the perspective of cognitive science , along with the findings of cognitive linguistics ,[ 45 ] with two defining aspects : ties with cognitive linguistics are part of the historical heritage of nlp , but they have been less frequently addressed since the statistical turn during the 1990s .\n",
      "natural language processing ( nlp ) is an interdisciplinary subfield of linguistics , computer science , and artificial intelligence concerned with the interactions between computers and human language , in particular how to program computers to process and analyze large amounts of natural language data .\n",
      "challenges in natural language processing frequently involve speech recognition , natural - language understanding , and natural - language generation .\n",
      "the premise of symbolic nlp is well - summarized by john searle ' s chinese room experiment : given a collection\n"
     ]
    }
   ],
   "source": [
    "# 1.5 - Summary \n",
    "\n",
    "\n",
    "def summary_based_on_sent_count(how_many_sent):\n",
    "    return list(ranked_sent)[:how_many_sent]\n",
    "    # Returning the first n sentences of the sorted sentence list \n",
    "    # which were sorted in the descending order based on the freq\n",
    "\n",
    "    \n",
    "def summary_based_word_count(word_count):\n",
    "    res = \"\"\n",
    "    s_index = 0\n",
    "    w_index = 0\n",
    "    w_count = 0\n",
    "    s_words = []\n",
    "    spc = \"\"\n",
    "    new_ln = \"\"\n",
    "    sents = list(ranked_sent)\n",
    "    \n",
    "    while w_count < word_count: # reading a new sent and tokenizing it\n",
    "        if len(s_words) == 0:\n",
    "            s_words = wordpunct_tokenize(sents[s_index])\n",
    "            w_index = 0\n",
    "            spc = \"\"\n",
    "            if len(res)>0:\n",
    "                new_ln = \"\\n\"\n",
    "        if w_index<len(s_words):\n",
    "            res += new_ln + spc + s_words[w_index]\n",
    "            w_index += 1\n",
    "            w_count += 1\n",
    "            spc = \" \"\n",
    "            new_ln = \"\"\n",
    "        else:\n",
    "            s_words = [] # reading another sentence now\n",
    "            s_index += 1\n",
    "    return res\n",
    "\n",
    "\n",
    "def summary_based_on_percent(percent):\n",
    "    \n",
    "    w_count = 0\n",
    "    tot_words = len(my_words)\n",
    "    w_count = (percent/100)*tot_words\n",
    "    return summary_based_word_count(w_count)\n",
    "\n",
    "print('Summary based on sentence count: \\n')\n",
    "print(summary_based_on_sent_count(2))\n",
    "\n",
    "print('\\n\\nSummary based on word count: \\n')\n",
    "print(summary_based_word_count(100))\n",
    "\n",
    "print('\\n\\nSummary based on Percentage: \\n')\n",
    "print(summary_based_on_percent(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8d27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab39d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc76abea",
   "metadata": {},
   "source": [
    "## Task 2 - Text Summarization with N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2a967d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a2eb26be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-grams: \n",
      " ['natural language', 'language processing', 'processing (', '( nlp', 'nlp )', ') is', 'is an', 'an interdisciplinary', 'interdisciplinary subfield', 'subfield of', 'of linguistics', 'linguistics ,', ', computer', 'computer science', 'science ,', ', and', 'and artificial', 'artificial intelligence', 'intelligence concerned', 'concerned with'] \n",
      "\n",
      "tri-grams: \n",
      " ['natural language processing', 'language processing (', 'processing ( nlp', '( nlp )', 'nlp ) is', ') is an', 'is an interdisciplinary', 'an interdisciplinary subfield', 'interdisciplinary subfield of', 'subfield of linguistics', 'of linguistics ,', 'linguistics , computer', ', computer science', 'computer science ,', 'science , and', ', and artificial', 'and artificial intelligence', 'artificial intelligence concerned', 'intelligence concerned with', 'concerned with the'] \n",
      "\n",
      "4-grams: \n",
      " ['natural language processing (', 'language processing ( nlp', 'processing ( nlp )', '( nlp ) is', 'nlp ) is an', ') is an interdisciplinary', 'is an interdisciplinary subfield', 'an interdisciplinary subfield of', 'interdisciplinary subfield of linguistics', 'subfield of linguistics ,', 'of linguistics , computer', 'linguistics , computer science', ', computer science ,', 'computer science , and', 'science , and artificial', ', and artificial intelligence', 'and artificial intelligence concerned', 'artificial intelligence concerned with', 'intelligence concerned with the', 'concerned with the interactions'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Generating n-grams from the text\n",
    "def gen_ngrams(text, n):\n",
    "    n_grams = ngrams(word_tokenize(text.lower()), n)\n",
    "    return [' '.join(g) for g in n_grams]\n",
    "\n",
    "\n",
    "grams_res_2 = gen_ngrams(content, 2)\n",
    "print('bi-grams: \\n', grams_res_2[0:20], '\\n')\n",
    "\n",
    "grams_res_3 = gen_ngrams(content, 3)\n",
    "print('tri-grams: \\n', grams_res_3[0:20], '\\n')\n",
    "\n",
    "grams_res_4 = gen_ngrams(content, 4)\n",
    "print('4-grams: \\n', grams_res_4[0:20], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8c9b0ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 1434 samples and 1518 outcomes>\n",
      "[('natural language processing', 12), ('language processing .', 5), ('in natural language', 4), ('( e.g. ,', 4), ('of natural language', 3), (', however ,', 3), ('] in the', 3), (', e.g. ,', 3), ('grammar , [', 3), ('language processing (', 2), ('processing ( nlp', 2), ('( nlp )', 2), ('is an interdisciplinary', 2), ('of linguistics ,', 2), ('data . the', 2), ('of documents ,', 2), ('natural language .', 2), ('of symbolic nlp', 2), ('hand-written rules .', 2), ('in the late', 2)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2.2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# a) freq dist to calculate the n-gram frequencies\n",
    "def display_n_grams(n):\n",
    "    n_grams = gen_ngrams(content, n)\n",
    "    freq_grams_res = FreqDist(n_grams)\n",
    "    print(freq_grams_res)\n",
    "    print(freq_grams_res.most_common(20))\n",
    "    freq_grams_res.plot(20)\n",
    "    plt.show()\n",
    "    \n",
    "display_n_grams(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a8af8507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('natural language processing', 1.0), ('language processing (', 0.16666666666666666), ('processing ( nlp', 0.16666666666666666), ('( nlp )', 0.16666666666666666), ('nlp ) is', 0.08333333333333333), (') is an', 0.08333333333333333), ('is an interdisciplinary', 0.16666666666666666), ('an interdisciplinary subfield', 0.08333333333333333), ('interdisciplinary subfield of', 0.08333333333333333), ('subfield of linguistics', 0.08333333333333333), ('of linguistics ,', 0.16666666666666666), ('linguistics , computer', 0.08333333333333333), (', computer science', 0.08333333333333333), ('computer science ,', 0.08333333333333333), ('science , and', 0.08333333333333333), (', and artificial', 0.08333333333333333), ('and artificial intelligence', 0.08333333333333333), ('artificial intelligence concerned', 0.08333333333333333), ('intelligence concerned with', 0.08333333333333333), ('concerned with the', 0.08333333333333333), ('with the interactions', 0.08333333333333333), ('the interactions between', 0.08333333333333333), ('interactions between computers', 0.08333333333333333), ('between computers and', 0.08333333333333333), ('computers and human', 0.08333333333333333), ('and human language', 0.08333333333333333), ('human language ,', 0.08333333333333333), ('language , in', 0.08333333333333333), (', in particular', 0.08333333333333333), ('in particular how', 0.08333333333333333), ('particular how to', 0.08333333333333333), ('how to program', 0.08333333333333333), ('to program computers', 0.08333333333333333), ('program computers to', 0.08333333333333333), ('computers to process', 0.08333333333333333), ('to process and', 0.08333333333333333), ('process and analyze', 0.08333333333333333), ('and analyze large', 0.08333333333333333), ('analyze large amounts', 0.08333333333333333), ('large amounts of', 0.08333333333333333), ('amounts of natural', 0.08333333333333333), ('of natural language', 0.25), ('natural language data', 0.08333333333333333), ('language data .', 0.08333333333333333), ('data . the', 0.16666666666666666), ('. the goal', 0.08333333333333333), ('the goal is', 0.08333333333333333), ('goal is a', 0.08333333333333333), ('is a computer', 0.08333333333333333), ('a computer capable', 0.08333333333333333), ('computer capable of', 0.08333333333333333), ('capable of ``', 0.08333333333333333), ('of `` understanding', 0.08333333333333333), (\"`` understanding ''\", 0.08333333333333333), (\"understanding '' the\", 0.08333333333333333), (\"'' the contents\", 0.08333333333333333), ('the contents of', 0.08333333333333333), ('contents of documents', 0.08333333333333333), ('of documents ,', 0.16666666666666666), ('documents , including', 0.08333333333333333), (', including the', 0.08333333333333333), ('including the contextual', 0.08333333333333333), ('the contextual nuances', 0.08333333333333333), ('contextual nuances of', 0.08333333333333333), ('nuances of the', 0.08333333333333333), ('of the language', 0.08333333333333333), ('the language within', 0.08333333333333333), ('language within them', 0.08333333333333333), ('within them .', 0.08333333333333333), ('them . the', 0.08333333333333333), ('. the technology', 0.08333333333333333), ('the technology can', 0.08333333333333333), ('technology can then', 0.08333333333333333), ('can then accurately', 0.08333333333333333), ('then accurately extract', 0.08333333333333333), ('accurately extract information', 0.08333333333333333), ('extract information and', 0.08333333333333333), ('information and insights', 0.08333333333333333), ('and insights contained', 0.08333333333333333), ('insights contained in', 0.08333333333333333), ('contained in the', 0.08333333333333333), ('in the documents', 0.08333333333333333), ('the documents as', 0.08333333333333333), ('documents as well', 0.08333333333333333), ('as well as', 0.08333333333333333), ('well as categorize', 0.08333333333333333), ('as categorize and', 0.08333333333333333), ('categorize and organize', 0.08333333333333333), ('and organize the', 0.08333333333333333), ('organize the documents', 0.08333333333333333), ('the documents themselves', 0.08333333333333333), ('documents themselves .', 0.08333333333333333), ('themselves . challenges', 0.08333333333333333), ('. challenges in', 0.08333333333333333), ('challenges in natural', 0.08333333333333333), ('in natural language', 0.3333333333333333), ('language processing frequently', 0.08333333333333333), ('processing frequently involve', 0.08333333333333333), ('frequently involve speech', 0.08333333333333333), ('involve speech recognition', 0.08333333333333333), ('speech recognition ,', 0.08333333333333333), ('recognition , natural-language', 0.08333333333333333), (', natural-language understanding', 0.08333333333333333), ('natural-language understanding ,', 0.08333333333333333), ('understanding , and', 0.08333333333333333), (', and natural-language', 0.08333333333333333), ('and natural-language generation', 0.08333333333333333), ('natural-language generation .', 0.08333333333333333), ('generation . natural', 0.08333333333333333), ('. natural language', 0.08333333333333333), ('language processing has', 0.08333333333333333), ('processing has its', 0.08333333333333333), ('has its roots', 0.08333333333333333), ('its roots in', 0.08333333333333333), ('roots in the', 0.08333333333333333), ('in the 1950s', 0.08333333333333333), ('the 1950s .', 0.08333333333333333), ('1950s . already', 0.08333333333333333), ('. already in', 0.08333333333333333), ('already in 1950', 0.08333333333333333), ('in 1950 ,', 0.08333333333333333), ('1950 , alan', 0.08333333333333333), (', alan turing', 0.08333333333333333), ('alan turing published', 0.08333333333333333), ('turing published an', 0.08333333333333333), ('published an article', 0.08333333333333333), ('an article titled', 0.08333333333333333), ('article titled ``', 0.08333333333333333), ('titled `` computing', 0.08333333333333333), ('`` computing machinery', 0.08333333333333333), ('computing machinery and', 0.08333333333333333), ('machinery and intelligence', 0.08333333333333333), (\"and intelligence ''\", 0.08333333333333333), (\"intelligence '' which\", 0.08333333333333333), (\"'' which proposed\", 0.08333333333333333), ('which proposed what', 0.08333333333333333), ('proposed what is', 0.08333333333333333), ('what is now', 0.08333333333333333), ('is now called', 0.08333333333333333), ('now called the', 0.08333333333333333), ('called the turing', 0.08333333333333333), ('the turing test', 0.08333333333333333), ('turing test as', 0.08333333333333333), ('test as a', 0.08333333333333333), ('as a criterion', 0.08333333333333333), ('a criterion of', 0.08333333333333333), ('criterion of intelligence', 0.08333333333333333), ('of intelligence ,', 0.08333333333333333), ('intelligence , though', 0.08333333333333333), (', though at', 0.08333333333333333), ('though at the', 0.08333333333333333), ('at the time', 0.08333333333333333), ('the time that', 0.08333333333333333), ('time that was', 0.08333333333333333), ('that was not', 0.08333333333333333), ('was not articulated', 0.08333333333333333), ('not articulated as', 0.08333333333333333), ('articulated as a', 0.08333333333333333), ('as a problem', 0.08333333333333333), ('a problem separate', 0.08333333333333333), ('problem separate from', 0.08333333333333333), ('separate from artificial', 0.08333333333333333), ('from artificial intelligence', 0.08333333333333333), ('artificial intelligence .', 0.08333333333333333), ('intelligence . the', 0.08333333333333333), ('. the proposed', 0.08333333333333333), ('the proposed test', 0.08333333333333333), ('proposed test includes', 0.08333333333333333), ('test includes a', 0.08333333333333333), ('includes a task', 0.08333333333333333), ('a task that', 0.08333333333333333), ('task that involves', 0.08333333333333333), ('that involves the', 0.08333333333333333), ('involves the automated', 0.08333333333333333), ('the automated interpretation', 0.08333333333333333), ('automated interpretation and', 0.08333333333333333), ('interpretation and generation', 0.08333333333333333), ('and generation of', 0.08333333333333333), ('generation of natural', 0.08333333333333333), ('natural language .', 0.16666666666666666), ('language . the', 0.08333333333333333), ('. the premise', 0.08333333333333333), ('the premise of', 0.08333333333333333), ('premise of symbolic', 0.08333333333333333), ('of symbolic nlp', 0.16666666666666666), ('symbolic nlp is', 0.08333333333333333), ('nlp is well-summarized', 0.08333333333333333), ('is well-summarized by', 0.08333333333333333), ('well-summarized by john', 0.08333333333333333), ('by john searle', 0.08333333333333333), (\"john searle 's\", 0.08333333333333333), (\"searle 's chinese\", 0.08333333333333333), (\"'s chinese room\", 0.08333333333333333), ('chinese room experiment', 0.08333333333333333), ('room experiment :', 0.08333333333333333), ('experiment : given', 0.08333333333333333), (': given a', 0.08333333333333333), ('given a collection', 0.08333333333333333), ('a collection of', 0.08333333333333333), ('collection of rules', 0.08333333333333333), ('of rules (', 0.08333333333333333), ('rules ( e.g.', 0.08333333333333333), ('( e.g. ,', 0.3333333333333333), ('e.g. , a', 0.08333333333333333), (', a chinese', 0.08333333333333333), ('a chinese phrasebook', 0.08333333333333333), ('chinese phrasebook ,', 0.08333333333333333), ('phrasebook , with', 0.08333333333333333), (', with questions', 0.08333333333333333), ('with questions and', 0.08333333333333333), ('questions and matching', 0.08333333333333333), ('and matching answers', 0.08333333333333333), ('matching answers )', 0.08333333333333333), ('answers ) ,', 0.08333333333333333), (') , the', 0.08333333333333333), (', the computer', 0.08333333333333333), ('the computer emulates', 0.08333333333333333), ('computer emulates natural', 0.08333333333333333), ('emulates natural language', 0.08333333333333333), ('natural language understanding', 0.08333333333333333), ('language understanding (', 0.08333333333333333), ('understanding ( or', 0.08333333333333333), ('( or other', 0.08333333333333333), ('or other nlp', 0.08333333333333333), ('other nlp tasks', 0.08333333333333333), ('nlp tasks )', 0.08333333333333333), ('tasks ) by', 0.08333333333333333), (') by applying', 0.08333333333333333), ('by applying those', 0.08333333333333333), ('applying those rules', 0.08333333333333333), ('those rules to', 0.08333333333333333), ('rules to the', 0.08333333333333333), ('to the data', 0.08333333333333333), ('the data it', 0.08333333333333333), ('data it confronts', 0.08333333333333333), ('it confronts .', 0.08333333333333333), ('confronts . up', 0.08333333333333333), ('. up to', 0.08333333333333333), ('up to the', 0.08333333333333333), ('to the 1980s', 0.08333333333333333), ('the 1980s ,', 0.08333333333333333), ('1980s , most', 0.08333333333333333), (', most natural', 0.08333333333333333), ('most natural language', 0.08333333333333333), ('language processing systems', 0.08333333333333333), ('processing systems were', 0.08333333333333333), ('systems were based', 0.08333333333333333), ('were based on', 0.08333333333333333), ('based on complex', 0.08333333333333333), ('on complex sets', 0.08333333333333333), ('complex sets of', 0.08333333333333333), ('sets of hand-written', 0.08333333333333333), ('of hand-written rules', 0.08333333333333333), ('hand-written rules .', 0.16666666666666666), ('rules . starting', 0.08333333333333333), ('. starting in', 0.08333333333333333), ('starting in the', 0.08333333333333333), ('in the late', 0.16666666666666666), ('the late 1980s', 0.16666666666666666), ('late 1980s ,', 0.08333333333333333), ('1980s , however', 0.08333333333333333), (', however ,', 0.25), ('however , there', 0.08333333333333333), (', there was', 0.08333333333333333), ('there was a', 0.08333333333333333), ('was a revolution', 0.08333333333333333), ('a revolution in', 0.08333333333333333), ('revolution in natural', 0.08333333333333333), ('language processing with', 0.08333333333333333), ('processing with the', 0.08333333333333333), ('with the introduction', 0.08333333333333333), ('the introduction of', 0.08333333333333333), ('introduction of machine', 0.08333333333333333), ('of machine learning', 0.16666666666666666), ('machine learning algorithms', 0.16666666666666666), ('learning algorithms for', 0.08333333333333333), ('algorithms for language', 0.08333333333333333), ('for language processing', 0.08333333333333333), ('language processing .', 0.4166666666666667), ('processing . this', 0.08333333333333333), ('. this was', 0.08333333333333333), ('this was due', 0.08333333333333333), ('was due to', 0.08333333333333333), ('due to both', 0.08333333333333333), ('to both the', 0.08333333333333333), ('both the steady', 0.08333333333333333), ('the steady increase', 0.08333333333333333), ('steady increase in', 0.08333333333333333), ('increase in computational', 0.08333333333333333), ('in computational power', 0.08333333333333333), ('computational power (', 0.08333333333333333), ('power ( see', 0.08333333333333333), ('( see moore', 0.08333333333333333), (\"see moore 's\", 0.08333333333333333), (\"moore 's law\", 0.08333333333333333), (\"'s law )\", 0.08333333333333333), ('law ) and', 0.08333333333333333), (') and the', 0.08333333333333333), ('and the gradual', 0.08333333333333333), ('the gradual lessening', 0.08333333333333333), ('gradual lessening of', 0.08333333333333333), ('lessening of the', 0.08333333333333333), ('of the dominance', 0.08333333333333333), ('the dominance of', 0.08333333333333333), ('dominance of chomskyan', 0.08333333333333333), ('of chomskyan theories', 0.08333333333333333), ('chomskyan theories of', 0.08333333333333333), ('theories of linguistics', 0.08333333333333333), ('of linguistics (', 0.08333333333333333), ('linguistics ( e.g', 0.08333333333333333), ('( e.g .', 0.08333333333333333), ('e.g . transformational', 0.08333333333333333), ('. transformational grammar', 0.08333333333333333), ('transformational grammar )', 0.08333333333333333), ('grammar ) ,', 0.08333333333333333), (') , whose', 0.08333333333333333), (', whose theoretical', 0.08333333333333333), ('whose theoretical underpinnings', 0.08333333333333333), ('theoretical underpinnings discouraged', 0.08333333333333333), ('underpinnings discouraged the', 0.08333333333333333), ('discouraged the sort', 0.08333333333333333), ('the sort of', 0.08333333333333333), ('sort of corpus', 0.08333333333333333), ('of corpus linguistics', 0.08333333333333333), ('corpus linguistics that', 0.08333333333333333), ('linguistics that underlies', 0.08333333333333333), ('that underlies the', 0.08333333333333333), ('underlies the machine-learning', 0.08333333333333333), ('the machine-learning approach', 0.08333333333333333), ('machine-learning approach to', 0.08333333333333333), ('approach to language', 0.08333333333333333), ('to language processing', 0.08333333333333333), ('processing . [', 0.08333333333333333), ('. [ 7', 0.08333333333333333), ('[ 7 ]', 0.08333333333333333), ('7 ] in', 0.08333333333333333), ('] in the', 0.25), ('in the 2010s', 0.08333333333333333), ('the 2010s ,', 0.08333333333333333), ('2010s , representation', 0.08333333333333333), (', representation learning', 0.08333333333333333), ('representation learning and', 0.08333333333333333), ('learning and deep', 0.08333333333333333), ('and deep neural', 0.08333333333333333), ('deep neural network-style', 0.08333333333333333), ('neural network-style machine', 0.08333333333333333), ('network-style machine learning', 0.08333333333333333), ('machine learning methods', 0.08333333333333333), ('learning methods became', 0.08333333333333333), ('methods became widespread', 0.08333333333333333), ('became widespread in', 0.08333333333333333), ('widespread in natural', 0.08333333333333333), ('processing . that', 0.08333333333333333), ('. that popularity', 0.08333333333333333), ('that popularity was', 0.08333333333333333), ('popularity was due', 0.08333333333333333), ('was due partly', 0.08333333333333333), ('due partly to', 0.08333333333333333), ('partly to a', 0.08333333333333333), ('to a flurry', 0.08333333333333333), ('a flurry of', 0.08333333333333333), ('flurry of results', 0.08333333333333333), ('of results showing', 0.08333333333333333), ('results showing that', 0.08333333333333333), ('showing that such', 0.08333333333333333), ('that such techniques', 0.08333333333333333), ('such techniques [', 0.08333333333333333), ('techniques [ 8', 0.08333333333333333), ('[ 8 ]', 0.08333333333333333), ('8 ] [', 0.08333333333333333), ('] [ 9', 0.08333333333333333), ('[ 9 ]', 0.08333333333333333), ('9 ] can', 0.08333333333333333), ('] can achieve', 0.08333333333333333), ('can achieve state-of-the-art', 0.08333333333333333), ('achieve state-of-the-art results', 0.08333333333333333), ('state-of-the-art results in', 0.08333333333333333), ('results in many', 0.08333333333333333), ('in many natural', 0.08333333333333333), ('many natural language', 0.08333333333333333), ('natural language tasks', 0.08333333333333333), ('language tasks ,', 0.08333333333333333), ('tasks , e.g.', 0.08333333333333333), (', e.g. ,', 0.25), ('e.g. , in', 0.08333333333333333), (', in language', 0.08333333333333333), ('in language modeling', 0.08333333333333333), ('language modeling [', 0.08333333333333333), ('modeling [ 10', 0.08333333333333333), ('[ 10 ]', 0.08333333333333333), ('10 ] and', 0.08333333333333333), ('] and parsing', 0.08333333333333333), ('and parsing .', 0.08333333333333333), ('parsing . [', 0.08333333333333333), ('. [ 11', 0.08333333333333333), ('[ 11 ]', 0.08333333333333333), ('11 ] [', 0.08333333333333333), ('] [ 12', 0.08333333333333333), ('[ 12 ]', 0.08333333333333333), ('12 ] this', 0.08333333333333333), ('] this is', 0.08333333333333333), ('this is increasingly', 0.08333333333333333), ('is increasingly important', 0.08333333333333333), ('increasingly important in', 0.08333333333333333), ('important in medicine', 0.08333333333333333), ('in medicine and', 0.08333333333333333), ('medicine and healthcare', 0.08333333333333333), ('and healthcare ,', 0.08333333333333333), ('healthcare , where', 0.08333333333333333), (', where nlp', 0.08333333333333333), ('where nlp helps', 0.08333333333333333), ('nlp helps analyze', 0.08333333333333333), ('helps analyze notes', 0.08333333333333333), ('analyze notes and', 0.08333333333333333), ('notes and text', 0.08333333333333333), ('and text in', 0.08333333333333333), ('text in electronic', 0.08333333333333333), ('in electronic health', 0.08333333333333333), ('electronic health records', 0.08333333333333333), ('health records that', 0.08333333333333333), ('records that would', 0.08333333333333333), ('that would otherwise', 0.08333333333333333), ('would otherwise be', 0.08333333333333333), ('otherwise be inaccessible', 0.08333333333333333), ('be inaccessible for', 0.08333333333333333), ('inaccessible for study', 0.08333333333333333), ('for study when', 0.08333333333333333), ('study when seeking', 0.08333333333333333), ('when seeking to', 0.08333333333333333), ('seeking to improve', 0.08333333333333333), ('to improve care', 0.08333333333333333), ('improve care .', 0.08333333333333333), ('care . [', 0.08333333333333333), ('. [ 13', 0.08333333333333333), ('[ 13 ]', 0.08333333333333333), ('13 ] in', 0.08333333333333333), ('in the early', 0.08333333333333333), ('the early days', 0.08333333333333333), ('early days ,', 0.08333333333333333), ('days , many', 0.08333333333333333), (', many language-processing', 0.08333333333333333), ('many language-processing systems', 0.08333333333333333), ('language-processing systems were', 0.08333333333333333), ('systems were designed', 0.08333333333333333), ('were designed by', 0.08333333333333333), ('designed by symbolic', 0.08333333333333333), ('by symbolic methods', 0.08333333333333333), ('symbolic methods ,', 0.08333333333333333), ('methods , i.e.', 0.08333333333333333), (', i.e. ,', 0.08333333333333333), ('i.e. , the', 0.08333333333333333), (', the hand-coding', 0.08333333333333333), ('the hand-coding of', 0.08333333333333333), ('hand-coding of a', 0.08333333333333333), ('of a set', 0.08333333333333333), ('a set of', 0.16666666666666666), ('set of rules', 0.08333333333333333), ('of rules ,', 0.08333333333333333), ('rules , coupled', 0.08333333333333333), (', coupled with', 0.08333333333333333), ('coupled with a', 0.08333333333333333), ('with a dictionary', 0.08333333333333333), ('a dictionary lookup', 0.08333333333333333), ('dictionary lookup :', 0.08333333333333333), ('lookup : [', 0.08333333333333333), (': [ 14', 0.08333333333333333), ('[ 14 ]', 0.08333333333333333), ('14 ] [', 0.08333333333333333), ('] [ 15', 0.08333333333333333), ('[ 15 ]', 0.08333333333333333), ('15 ] such', 0.08333333333333333), ('] such as', 0.08333333333333333), ('such as by', 0.08333333333333333), ('as by writing', 0.08333333333333333), ('by writing grammars', 0.08333333333333333), ('writing grammars or', 0.08333333333333333), ('grammars or devising', 0.08333333333333333), ('or devising heuristic', 0.08333333333333333), ('devising heuristic rules', 0.08333333333333333), ('heuristic rules for', 0.08333333333333333), ('rules for stemming', 0.08333333333333333), ('for stemming .', 0.08333333333333333), ('stemming . more', 0.08333333333333333), ('. more recent', 0.08333333333333333), ('more recent systems', 0.08333333333333333), ('recent systems based', 0.08333333333333333), ('systems based on', 0.08333333333333333), ('based on machine-learning', 0.08333333333333333), ('on machine-learning algorithms', 0.08333333333333333), ('machine-learning algorithms have', 0.16666666666666666), ('algorithms have many', 0.08333333333333333), ('have many advantages', 0.08333333333333333), ('many advantages over', 0.08333333333333333), ('advantages over hand-produced', 0.08333333333333333), ('over hand-produced rules', 0.08333333333333333), ('hand-produced rules :', 0.08333333333333333), ('rules : despite', 0.08333333333333333), (': despite the', 0.08333333333333333), ('despite the popularity', 0.08333333333333333), ('the popularity of', 0.08333333333333333), ('popularity of machine', 0.08333333333333333), ('machine learning in', 0.08333333333333333), ('learning in nlp', 0.08333333333333333), ('in nlp research', 0.16666666666666666), ('nlp research ,', 0.08333333333333333), ('research , symbolic', 0.08333333333333333), (', symbolic methods', 0.08333333333333333), ('symbolic methods are', 0.08333333333333333), ('methods are still', 0.08333333333333333), ('are still (', 0.08333333333333333), ('still ( 2020', 0.08333333333333333), ('( 2020 )', 0.08333333333333333), ('2020 ) commonly', 0.08333333333333333), (') commonly used', 0.08333333333333333), ('commonly used :', 0.08333333333333333), ('used : since', 0.08333333333333333), (': since the', 0.08333333333333333), ('since the so-called', 0.08333333333333333), ('the so-called ``', 0.08333333333333333), ('so-called `` statistical', 0.08333333333333333), ('`` statistical revolution', 0.08333333333333333), (\"statistical revolution ''\", 0.08333333333333333), (\"revolution '' [\", 0.08333333333333333), (\"'' [ 16\", 0.08333333333333333), ('[ 16 ]', 0.08333333333333333), ('16 ] [', 0.08333333333333333), ('] [ 17', 0.08333333333333333), ('[ 17 ]', 0.08333333333333333), ('17 ] in', 0.08333333333333333), ('late 1980s and', 0.08333333333333333), ('1980s and mid-1990s', 0.08333333333333333), ('and mid-1990s ,', 0.08333333333333333), ('mid-1990s , much', 0.08333333333333333), (', much natural', 0.08333333333333333), ('much natural language', 0.08333333333333333), ('language processing research', 0.08333333333333333), ('processing research has', 0.08333333333333333), ('research has relied', 0.08333333333333333), ('has relied heavily', 0.08333333333333333), ('relied heavily on', 0.08333333333333333), ('heavily on machine', 0.08333333333333333), ('on machine learning', 0.08333333333333333), ('machine learning .', 0.16666666666666666), ('learning . the', 0.08333333333333333), ('. the machine-learning', 0.08333333333333333), ('the machine-learning paradigm', 0.08333333333333333), ('machine-learning paradigm calls', 0.08333333333333333), ('paradigm calls instead', 0.08333333333333333), ('calls instead for', 0.08333333333333333), ('instead for using', 0.08333333333333333), ('for using statistical', 0.08333333333333333), ('using statistical inference', 0.08333333333333333), ('statistical inference to', 0.08333333333333333), ('inference to automatically', 0.08333333333333333), ('to automatically learn', 0.08333333333333333), ('automatically learn such', 0.08333333333333333), ('learn such rules', 0.08333333333333333), ('such rules through', 0.08333333333333333), ('rules through the', 0.08333333333333333), ('through the analysis', 0.08333333333333333), ('the analysis of', 0.08333333333333333), ('analysis of large', 0.08333333333333333), ('of large corpora', 0.08333333333333333), ('large corpora (', 0.08333333333333333), ('corpora ( the', 0.08333333333333333), ('( the plural', 0.08333333333333333), ('the plural form', 0.08333333333333333), ('plural form of', 0.08333333333333333), ('form of corpus', 0.08333333333333333), ('of corpus ,', 0.08333333333333333), ('corpus , is', 0.08333333333333333), (', is a', 0.08333333333333333), ('is a set', 0.08333333333333333), ('set of documents', 0.08333333333333333), ('documents , possibly', 0.08333333333333333), (', possibly with', 0.08333333333333333), ('possibly with human', 0.08333333333333333), ('with human or', 0.08333333333333333), ('human or computer', 0.08333333333333333), ('or computer annotations', 0.08333333333333333), ('computer annotations )', 0.08333333333333333), ('annotations ) of', 0.08333333333333333), (') of typical', 0.08333333333333333), ('of typical real-world', 0.08333333333333333), ('typical real-world examples', 0.08333333333333333), ('real-world examples .', 0.08333333333333333), ('examples . many', 0.08333333333333333), ('. many different', 0.08333333333333333), ('many different classes', 0.08333333333333333), ('different classes of', 0.08333333333333333), ('classes of machine-learning', 0.08333333333333333), ('of machine-learning algorithms', 0.08333333333333333), ('algorithms have been', 0.08333333333333333), ('have been applied', 0.08333333333333333), ('been applied to', 0.08333333333333333), ('applied to natural-language-processing', 0.08333333333333333), ('to natural-language-processing tasks', 0.08333333333333333), ('natural-language-processing tasks .', 0.08333333333333333), ('tasks . these', 0.08333333333333333), ('. these algorithms', 0.08333333333333333), ('these algorithms take', 0.08333333333333333), ('algorithms take as', 0.08333333333333333), ('take as input', 0.08333333333333333), ('as input a', 0.08333333333333333), ('input a large', 0.08333333333333333), ('a large set', 0.08333333333333333), ('large set of', 0.08333333333333333), ('set of ``', 0.08333333333333333), ('of `` features', 0.08333333333333333), (\"`` features ''\", 0.08333333333333333), (\"features '' that\", 0.08333333333333333), (\"'' that are\", 0.08333333333333333), ('that are generated', 0.08333333333333333), ('are generated from', 0.08333333333333333), ('generated from the', 0.08333333333333333), ('from the input', 0.08333333333333333), ('the input data', 0.16666666666666666), ('input data .', 0.16666666666666666), ('data . increasingly', 0.08333333333333333), ('. increasingly ,', 0.08333333333333333), ('increasingly , however', 0.08333333333333333), ('however , research', 0.08333333333333333), (', research has', 0.16666666666666666), ('research has focused', 0.16666666666666666), ('has focused on', 0.16666666666666666), ('focused on statistical', 0.16666666666666666), ('on statistical models', 0.16666666666666666), ('statistical models ,', 0.16666666666666666), ('models , which', 0.16666666666666666), (', which make', 0.16666666666666666), ('which make soft', 0.16666666666666666), ('make soft ,', 0.16666666666666666), ('soft , probabilistic', 0.16666666666666666), (', probabilistic decisions', 0.16666666666666666), ('probabilistic decisions based', 0.16666666666666666), ('decisions based on', 0.16666666666666666), ('based on attaching', 0.16666666666666666), ('on attaching real-valued', 0.16666666666666666), ('attaching real-valued weights', 0.16666666666666666), ('real-valued weights to', 0.16666666666666666), ('weights to each', 0.08333333333333333), ('to each input', 0.08333333333333333), ('each input feature', 0.08333333333333333), ('input feature (', 0.08333333333333333), ('feature ( complex-valued', 0.08333333333333333), ('( complex-valued embeddings', 0.08333333333333333), ('complex-valued embeddings ,', 0.08333333333333333), ('embeddings , [', 0.08333333333333333), (', [ 18', 0.08333333333333333), ('[ 18 ]', 0.08333333333333333), ('18 ] and', 0.08333333333333333), ('] and neural', 0.08333333333333333), ('and neural networks', 0.08333333333333333), ('neural networks in', 0.08333333333333333), ('networks in general', 0.08333333333333333), ('in general have', 0.08333333333333333), ('general have also', 0.08333333333333333), ('have also been', 0.08333333333333333), ('also been proposed', 0.08333333333333333), ('been proposed ,', 0.08333333333333333), ('proposed , for', 0.08333333333333333), (', for e.g', 0.08333333333333333), ('for e.g .', 0.08333333333333333), ('e.g . speech', 0.08333333333333333), ('. speech [', 0.08333333333333333), ('speech [ 19', 0.08333333333333333), ('[ 19 ]', 0.08333333333333333), ('19 ] )', 0.08333333333333333), ('] ) .', 0.08333333333333333), (') . such', 0.08333333333333333), ('. such models', 0.16666666666666666), ('such models have', 0.08333333333333333), ('models have the', 0.08333333333333333), ('have the advantage', 0.08333333333333333), ('the advantage that', 0.08333333333333333), ('advantage that they', 0.08333333333333333), ('that they can', 0.08333333333333333), ('they can express', 0.08333333333333333), ('can express the', 0.08333333333333333), ('express the relative', 0.08333333333333333), ('the relative certainty', 0.08333333333333333), ('relative certainty of', 0.08333333333333333), ('certainty of many', 0.08333333333333333), ('of many different', 0.08333333333333333), ('many different possible', 0.08333333333333333), ('different possible answers', 0.08333333333333333), ('possible answers rather', 0.08333333333333333), ('answers rather than', 0.08333333333333333), ('rather than only', 0.08333333333333333), ('than only one', 0.08333333333333333), ('only one ,', 0.08333333333333333), ('one , producing', 0.08333333333333333), (', producing more', 0.08333333333333333), ('producing more reliable', 0.08333333333333333), ('more reliable results', 0.16666666666666666), ('reliable results when', 0.16666666666666666), ('results when such', 0.08333333333333333), ('when such a', 0.08333333333333333), ('such a model', 0.08333333333333333), ('a model is', 0.08333333333333333), ('model is included', 0.08333333333333333), ('is included as', 0.08333333333333333), ('included as a', 0.08333333333333333), ('as a component', 0.08333333333333333), ('a component of', 0.08333333333333333), ('component of a', 0.08333333333333333), ('of a larger', 0.08333333333333333), ('a larger system', 0.16666666666666666), ('larger system .', 0.08333333333333333), ('system . some', 0.08333333333333333), ('. some of', 0.16666666666666666), ('some of the', 0.16666666666666666), ('of the earliest-used', 0.08333333333333333), ('the earliest-used machine', 0.08333333333333333), ('earliest-used machine learning', 0.08333333333333333), ('learning algorithms ,', 0.08333333333333333), ('algorithms , such', 0.08333333333333333), (', such as', 0.08333333333333333), ('such as decision', 0.08333333333333333), ('as decision trees', 0.08333333333333333), ('decision trees ,', 0.08333333333333333), ('trees , produced', 0.08333333333333333), (', produced systems', 0.08333333333333333), ('produced systems of', 0.08333333333333333), ('systems of hard', 0.08333333333333333), ('of hard if-then', 0.08333333333333333), ('hard if-then rules', 0.08333333333333333), ('if-then rules similar', 0.08333333333333333), ('rules similar to', 0.08333333333333333), ('similar to existing', 0.08333333333333333), ('to existing hand-written', 0.08333333333333333), ('existing hand-written rules', 0.08333333333333333), ('rules . however', 0.08333333333333333), ('. however ,', 0.16666666666666666), ('however , part-of-speech', 0.08333333333333333), (', part-of-speech tagging', 0.16666666666666666), ('part-of-speech tagging introduced', 0.08333333333333333), ('tagging introduced the', 0.08333333333333333), ('introduced the use', 0.08333333333333333), ('the use of', 0.16666666666666666), ('use of hidden', 0.08333333333333333), ('of hidden markov', 0.08333333333333333), ('hidden markov models', 0.08333333333333333), ('markov models to', 0.08333333333333333), ('models to natural', 0.08333333333333333), ('to natural language', 0.08333333333333333), ('language processing ,', 0.08333333333333333), ('processing , and', 0.08333333333333333), (', and increasingly', 0.08333333333333333), ('and increasingly ,', 0.08333333333333333), ('increasingly , research', 0.08333333333333333), ('weights to the', 0.08333333333333333), ('to the features', 0.08333333333333333), ('the features making', 0.08333333333333333), ('features making up', 0.08333333333333333), ('making up the', 0.08333333333333333), ('up the input', 0.08333333333333333), ('. the cache', 0.08333333333333333), ('the cache language', 0.08333333333333333), ('cache language models', 0.08333333333333333), ('language models upon', 0.08333333333333333), ('models upon which', 0.08333333333333333), ('upon which many', 0.08333333333333333), ('which many speech', 0.08333333333333333), ('many speech recognition', 0.08333333333333333), ('speech recognition systems', 0.08333333333333333), ('recognition systems now', 0.08333333333333333), ('systems now rely', 0.08333333333333333), ('now rely are', 0.08333333333333333), ('rely are examples', 0.08333333333333333), ('are examples of', 0.08333333333333333), ('examples of such', 0.08333333333333333), ('of such statistical', 0.08333333333333333), ('such statistical models', 0.08333333333333333), ('statistical models .', 0.08333333333333333), ('models . such', 0.08333333333333333), ('such models are', 0.08333333333333333), ('models are generally', 0.08333333333333333), ('are generally more', 0.08333333333333333), ('generally more robust', 0.08333333333333333), ('more robust when', 0.08333333333333333), ('robust when given', 0.08333333333333333), ('when given unfamiliar', 0.08333333333333333), ('given unfamiliar input', 0.08333333333333333), ('unfamiliar input ,', 0.08333333333333333), ('input , especially', 0.08333333333333333), (', especially input', 0.08333333333333333), ('especially input that', 0.08333333333333333), ('input that contains', 0.08333333333333333), ('that contains errors', 0.08333333333333333), ('contains errors (', 0.08333333333333333), ('errors ( as', 0.08333333333333333), ('( as is', 0.08333333333333333), ('as is very', 0.08333333333333333), ('is very common', 0.08333333333333333), ('very common for', 0.08333333333333333), ('common for real-world', 0.08333333333333333), ('for real-world data', 0.08333333333333333), ('real-world data )', 0.08333333333333333), ('data ) ,', 0.08333333333333333), (') , and', 0.08333333333333333), (', and produce', 0.08333333333333333), ('and produce more', 0.08333333333333333), ('produce more reliable', 0.08333333333333333), ('results when integrated', 0.08333333333333333), ('when integrated into', 0.08333333333333333), ('integrated into a', 0.08333333333333333), ('into a larger', 0.08333333333333333), ('larger system comprising', 0.08333333333333333), ('system comprising multiple', 0.08333333333333333), ('comprising multiple subtasks', 0.08333333333333333), ('multiple subtasks .', 0.08333333333333333), ('subtasks . since', 0.08333333333333333), ('. since the', 0.08333333333333333), ('since the neural', 0.08333333333333333), ('the neural turn', 0.08333333333333333), ('neural turn ,', 0.08333333333333333), ('turn , statistical', 0.08333333333333333), (', statistical methods', 0.08333333333333333), ('statistical methods in', 0.08333333333333333), ('methods in nlp', 0.08333333333333333), ('nlp research have', 0.08333333333333333), ('research have been', 0.08333333333333333), ('have been largely', 0.08333333333333333), ('been largely replaced', 0.08333333333333333), ('largely replaced by', 0.08333333333333333), ('replaced by neural', 0.08333333333333333), ('by neural networks', 0.08333333333333333), ('neural networks .', 0.08333333333333333), ('networks . however', 0.08333333333333333), ('however , they', 0.08333333333333333), (', they continue', 0.08333333333333333), ('they continue to', 0.08333333333333333), ('continue to be', 0.08333333333333333), ('to be relevant', 0.08333333333333333), ('be relevant for', 0.08333333333333333), ('relevant for contexts', 0.08333333333333333), ('for contexts in', 0.08333333333333333), ('contexts in which', 0.08333333333333333), ('in which statistical', 0.08333333333333333), ('which statistical interpretability', 0.08333333333333333), ('statistical interpretability and', 0.08333333333333333), ('interpretability and transparency', 0.08333333333333333), ('and transparency is', 0.08333333333333333), ('transparency is required', 0.08333333333333333), ('is required .', 0.08333333333333333), ('required . a', 0.08333333333333333), ('. a major', 0.08333333333333333), ('a major drawback', 0.08333333333333333), ('major drawback of', 0.08333333333333333), ('drawback of statistical', 0.08333333333333333), ('of statistical methods', 0.08333333333333333), ('statistical methods is', 0.08333333333333333), ('methods is that', 0.08333333333333333), ('is that they', 0.08333333333333333), ('that they require', 0.08333333333333333), ('they require elaborate', 0.08333333333333333), ('require elaborate feature', 0.08333333333333333), ('elaborate feature engineering', 0.08333333333333333), ('feature engineering .', 0.08333333333333333), ('engineering . since', 0.08333333333333333), ('. since 2015', 0.08333333333333333), ('since 2015 ,', 0.08333333333333333), ('2015 , [', 0.08333333333333333), (', [ 20', 0.08333333333333333), ('[ 20 ]', 0.08333333333333333), ('20 ] the', 0.08333333333333333), ('] the field', 0.08333333333333333), ('the field has', 0.08333333333333333), ('field has thus', 0.08333333333333333), ('has thus largely', 0.08333333333333333), ('thus largely abandoned', 0.08333333333333333), ('largely abandoned statistical', 0.08333333333333333), ('abandoned statistical methods', 0.08333333333333333), ('statistical methods and', 0.08333333333333333), ('methods and shifted', 0.08333333333333333), ('and shifted to', 0.08333333333333333), ('shifted to neural', 0.08333333333333333), ('to neural networks', 0.08333333333333333), ('neural networks for', 0.08333333333333333), ('networks for machine', 0.08333333333333333), ('for machine learning', 0.08333333333333333), ('learning . popular', 0.08333333333333333), ('. popular techniques', 0.08333333333333333), ('popular techniques include', 0.08333333333333333), ('techniques include the', 0.08333333333333333), ('include the use', 0.08333333333333333), ('use of word', 0.08333333333333333), ('of word embeddings', 0.08333333333333333), ('word embeddings to', 0.08333333333333333), ('embeddings to capture', 0.08333333333333333), ('to capture semantic', 0.08333333333333333), ('capture semantic properties', 0.08333333333333333), ('semantic properties of', 0.08333333333333333), ('properties of words', 0.08333333333333333), ('of words ,', 0.08333333333333333), ('words , and', 0.08333333333333333), (', and an', 0.08333333333333333), ('and an increase', 0.08333333333333333), ('an increase in', 0.08333333333333333), ('increase in end-to-end', 0.08333333333333333), ('in end-to-end learning', 0.08333333333333333), ('end-to-end learning of', 0.08333333333333333), ('learning of a', 0.08333333333333333), ('of a higher-level', 0.08333333333333333), ('a higher-level task', 0.08333333333333333), ('higher-level task (', 0.08333333333333333), ('task ( e.g.', 0.08333333333333333), ('e.g. , question', 0.08333333333333333), (', question answering', 0.08333333333333333), ('question answering )', 0.08333333333333333), ('answering ) instead', 0.08333333333333333), (') instead of', 0.08333333333333333), ('instead of relying', 0.08333333333333333), ('of relying on', 0.08333333333333333), ('relying on a', 0.08333333333333333), ('on a pipeline', 0.08333333333333333), ('a pipeline of', 0.08333333333333333), ('pipeline of separate', 0.08333333333333333), ('of separate intermediate', 0.08333333333333333), ('separate intermediate tasks', 0.08333333333333333), ('intermediate tasks (', 0.08333333333333333), ('tasks ( e.g.', 0.08333333333333333), ('e.g. , part-of-speech', 0.08333333333333333), ('part-of-speech tagging and', 0.08333333333333333), ('tagging and dependency', 0.08333333333333333), ('and dependency parsing', 0.08333333333333333), ('dependency parsing )', 0.08333333333333333), ('parsing ) .', 0.08333333333333333), (') . in', 0.08333333333333333), ('. in some', 0.08333333333333333), ('in some areas', 0.08333333333333333), ('some areas ,', 0.08333333333333333), ('areas , this', 0.08333333333333333), (', this shift', 0.08333333333333333), ('this shift has', 0.08333333333333333), ('shift has entailed', 0.08333333333333333), ('has entailed substantial', 0.08333333333333333), ('entailed substantial changes', 0.08333333333333333), ('substantial changes in', 0.08333333333333333), ('changes in how', 0.08333333333333333), ('in how nlp', 0.08333333333333333), ('how nlp systems', 0.08333333333333333), ('nlp systems are', 0.08333333333333333), ('systems are designed', 0.08333333333333333), ('are designed ,', 0.08333333333333333), ('designed , such', 0.08333333333333333), (', such that', 0.08333333333333333), ('such that deep', 0.08333333333333333), ('that deep neural', 0.08333333333333333), ('deep neural network-based', 0.08333333333333333), ('neural network-based approaches', 0.08333333333333333), ('network-based approaches may', 0.08333333333333333), ('approaches may be', 0.08333333333333333), ('may be viewed', 0.08333333333333333), ('be viewed as', 0.08333333333333333), ('viewed as a', 0.08333333333333333), ('as a new', 0.08333333333333333), ('a new paradigm', 0.08333333333333333), ('new paradigm distinct', 0.08333333333333333), ('paradigm distinct from', 0.08333333333333333), ('distinct from statistical', 0.08333333333333333), ('from statistical natural', 0.08333333333333333), ('statistical natural language', 0.08333333333333333), ('processing . for', 0.08333333333333333), ('. for instance', 0.08333333333333333), ('for instance ,', 0.08333333333333333), ('instance , the', 0.08333333333333333), (', the term', 0.08333333333333333), ('the term neural', 0.08333333333333333), ('term neural machine', 0.08333333333333333), ('neural machine translation', 0.08333333333333333), ('machine translation (', 0.16666666666666666), ('translation ( nmt', 0.08333333333333333), ('( nmt )', 0.08333333333333333), ('nmt ) emphasizes', 0.08333333333333333), (') emphasizes the', 0.08333333333333333), ('emphasizes the fact', 0.08333333333333333), ('the fact that', 0.08333333333333333), ('fact that deep', 0.08333333333333333), ('that deep learning-based', 0.08333333333333333), ('deep learning-based approaches', 0.08333333333333333), ('learning-based approaches to', 0.08333333333333333), ('approaches to machine', 0.08333333333333333), ('to machine translation', 0.08333333333333333), ('machine translation directly', 0.08333333333333333), ('translation directly learn', 0.08333333333333333), ('directly learn sequence-to-sequence', 0.08333333333333333), ('learn sequence-to-sequence transformations', 0.08333333333333333), ('sequence-to-sequence transformations ,', 0.08333333333333333), ('transformations , obviating', 0.08333333333333333), (', obviating the', 0.08333333333333333), ('obviating the need', 0.08333333333333333), ('the need for', 0.08333333333333333), ('need for intermediate', 0.08333333333333333), ('for intermediate steps', 0.08333333333333333), ('intermediate steps such', 0.08333333333333333), ('steps such as', 0.08333333333333333), ('such as word', 0.08333333333333333), ('as word alignment', 0.08333333333333333), ('word alignment and', 0.08333333333333333), ('alignment and language', 0.08333333333333333), ('and language modeling', 0.08333333333333333), ('language modeling that', 0.08333333333333333), ('modeling that was', 0.08333333333333333), ('that was used', 0.08333333333333333), ('was used in', 0.08333333333333333), ('used in statistical', 0.08333333333333333), ('in statistical machine', 0.08333333333333333), ('statistical machine translation', 0.08333333333333333), ('translation ( smt', 0.08333333333333333), ('( smt )', 0.08333333333333333), ('smt ) .', 0.08333333333333333), (') . the', 0.08333333333333333), ('. the following', 0.08333333333333333), ('the following is', 0.08333333333333333), ('following is a', 0.08333333333333333), ('is a list', 0.08333333333333333), ('a list of', 0.08333333333333333), ('list of some', 0.08333333333333333), ('of some of', 0.08333333333333333), ('of the most', 0.08333333333333333), ('the most commonly', 0.08333333333333333), ('most commonly researched', 0.08333333333333333), ('commonly researched tasks', 0.08333333333333333), ('researched tasks in', 0.08333333333333333), ('tasks in natural', 0.08333333333333333), ('processing . some', 0.08333333333333333), ('some of these', 0.08333333333333333), ('of these tasks', 0.08333333333333333), ('these tasks have', 0.08333333333333333), ('tasks have direct', 0.08333333333333333), ('have direct real-world', 0.08333333333333333), ('direct real-world applications', 0.08333333333333333), ('real-world applications ,', 0.08333333333333333), ('applications , while', 0.08333333333333333), (', while others', 0.08333333333333333), ('while others more', 0.08333333333333333), ('others more commonly', 0.08333333333333333), ('more commonly serve', 0.08333333333333333), ('commonly serve as', 0.08333333333333333), ('serve as subtasks', 0.08333333333333333), ('as subtasks that', 0.08333333333333333), ('subtasks that are', 0.08333333333333333), ('that are used', 0.08333333333333333), ('are used to', 0.08333333333333333), ('used to aid', 0.08333333333333333), ('to aid in', 0.08333333333333333), ('aid in solving', 0.08333333333333333), ('in solving larger', 0.08333333333333333), ('solving larger tasks', 0.08333333333333333), ('larger tasks .', 0.08333333333333333), ('tasks . though', 0.08333333333333333), ('. though natural', 0.08333333333333333), ('though natural language', 0.08333333333333333), ('language processing tasks', 0.08333333333333333), ('processing tasks are', 0.08333333333333333), ('tasks are closely', 0.08333333333333333), ('are closely intertwined', 0.08333333333333333), ('closely intertwined ,', 0.08333333333333333), ('intertwined , they', 0.08333333333333333), (', they can', 0.08333333333333333), ('they can be', 0.08333333333333333), ('can be subdivided', 0.08333333333333333), ('be subdivided into', 0.08333333333333333), ('subdivided into categories', 0.08333333333333333), ('into categories for', 0.08333333333333333), ('categories for convenience', 0.08333333333333333), ('for convenience .', 0.08333333333333333), ('convenience . a', 0.08333333333333333), ('. a coarse', 0.08333333333333333), ('a coarse division', 0.08333333333333333), ('coarse division is', 0.08333333333333333), ('division is given', 0.08333333333333333), ('is given below', 0.08333333333333333), ('given below .', 0.08333333333333333), ('below . based', 0.08333333333333333), ('. based on', 0.08333333333333333), ('based on long-standing', 0.08333333333333333), ('on long-standing trends', 0.08333333333333333), ('long-standing trends in', 0.08333333333333333), ('trends in the', 0.08333333333333333), ('in the field', 0.08333333333333333), ('the field ,', 0.08333333333333333), ('field , it', 0.08333333333333333), (', it is', 0.08333333333333333), ('it is possible', 0.08333333333333333), ('is possible to', 0.08333333333333333), ('possible to extrapolate', 0.08333333333333333), ('to extrapolate future', 0.08333333333333333), ('extrapolate future directions', 0.08333333333333333), ('future directions of', 0.08333333333333333), ('directions of nlp', 0.08333333333333333), ('of nlp .', 0.08333333333333333), ('nlp . as', 0.08333333333333333), ('. as of', 0.08333333333333333), ('as of 2020', 0.08333333333333333), ('of 2020 ,', 0.08333333333333333), ('2020 , three', 0.08333333333333333), (', three trends', 0.08333333333333333), ('three trends among', 0.08333333333333333), ('trends among the', 0.08333333333333333), ('among the topics', 0.08333333333333333), ('the topics of', 0.08333333333333333), ('topics of the', 0.08333333333333333), ('of the long-standing', 0.08333333333333333), ('the long-standing series', 0.08333333333333333), ('long-standing series of', 0.08333333333333333), ('series of conll', 0.08333333333333333), ('of conll shared', 0.08333333333333333), ('conll shared tasks', 0.16666666666666666), ('shared tasks can', 0.08333333333333333), ('tasks can be', 0.08333333333333333), ('can be observed', 0.08333333333333333), ('be observed :', 0.08333333333333333), ('observed : [', 0.08333333333333333), (': [ 41', 0.08333333333333333), ('[ 41 ]', 0.08333333333333333), ('41 ] most', 0.08333333333333333), ('] most higher-level', 0.08333333333333333), ('most higher-level nlp', 0.08333333333333333), ('higher-level nlp applications', 0.08333333333333333), ('nlp applications involve', 0.08333333333333333), ('applications involve aspects', 0.08333333333333333), ('involve aspects that', 0.08333333333333333), ('aspects that emulate', 0.08333333333333333), ('that emulate intelligent', 0.08333333333333333), ('emulate intelligent behaviour', 0.08333333333333333), ('intelligent behaviour and', 0.08333333333333333), ('behaviour and apparent', 0.08333333333333333), ('and apparent comprehension', 0.08333333333333333), ('apparent comprehension of', 0.08333333333333333), ('comprehension of natural', 0.08333333333333333), ('language . more', 0.08333333333333333), ('. more broadly', 0.08333333333333333), ('more broadly speaking', 0.08333333333333333), ('broadly speaking ,', 0.08333333333333333), ('speaking , the', 0.08333333333333333), (', the technical', 0.08333333333333333), ('the technical operationalization', 0.08333333333333333), ('technical operationalization of', 0.08333333333333333), ('operationalization of increasingly', 0.08333333333333333), ('of increasingly advanced', 0.08333333333333333), ('increasingly advanced aspects', 0.08333333333333333), ('advanced aspects of', 0.08333333333333333), ('aspects of cognitive', 0.08333333333333333), ('of cognitive behaviour', 0.08333333333333333), ('cognitive behaviour represents', 0.08333333333333333), ('behaviour represents one', 0.08333333333333333), ('represents one of', 0.08333333333333333), ('one of the', 0.08333333333333333), ('of the developmental', 0.08333333333333333), ('the developmental trajectories', 0.08333333333333333), ('developmental trajectories of', 0.08333333333333333), ('trajectories of nlp', 0.08333333333333333), ('of nlp (', 0.08333333333333333), ('nlp ( see', 0.08333333333333333), ('( see trends', 0.08333333333333333), ('see trends among', 0.08333333333333333), ('trends among conll', 0.08333333333333333), ('among conll shared', 0.08333333333333333), ('shared tasks above', 0.08333333333333333), ('tasks above )', 0.08333333333333333), ('above ) .', 0.08333333333333333), (') . cognition', 0.08333333333333333), ('. cognition refers', 0.08333333333333333), ('cognition refers to', 0.08333333333333333), ('refers to ``', 0.08333333333333333), ('to `` the', 0.08333333333333333), ('`` the mental', 0.08333333333333333), ('the mental action', 0.08333333333333333), ('mental action or', 0.08333333333333333), ('action or process', 0.08333333333333333), ('or process of', 0.08333333333333333), ('process of acquiring', 0.08333333333333333), ('of acquiring knowledge', 0.08333333333333333), ('acquiring knowledge and', 0.08333333333333333), ('knowledge and understanding', 0.08333333333333333), ('and understanding through', 0.08333333333333333), ('understanding through thought', 0.08333333333333333), ('through thought ,', 0.08333333333333333), ('thought , experience', 0.08333333333333333), (', experience ,', 0.08333333333333333), ('experience , and', 0.08333333333333333), (', and the', 0.08333333333333333), ('and the senses', 0.08333333333333333), ('the senses .', 0.08333333333333333), ('senses . ``', 0.08333333333333333), ('. `` [', 0.08333333333333333), ('`` [ 42', 0.08333333333333333), ('[ 42 ]', 0.08333333333333333), ('42 ] cognitive', 0.08333333333333333), ('] cognitive science', 0.08333333333333333), ('cognitive science is', 0.08333333333333333), ('science is the', 0.08333333333333333), ('is the interdisciplinary', 0.08333333333333333), ('the interdisciplinary ,', 0.08333333333333333), ('interdisciplinary , scientific', 0.08333333333333333), (', scientific study', 0.08333333333333333), ('scientific study of', 0.08333333333333333), ('study of the', 0.08333333333333333), ('of the mind', 0.08333333333333333), ('the mind and', 0.08333333333333333), ('mind and its', 0.08333333333333333), ('and its processes', 0.08333333333333333), ('its processes .', 0.08333333333333333), ('processes . [', 0.08333333333333333), ('. [ 43', 0.08333333333333333), ('[ 43 ]', 0.08333333333333333), ('43 ] cognitive', 0.08333333333333333), ('] cognitive linguistics', 0.08333333333333333), ('cognitive linguistics is', 0.08333333333333333), ('linguistics is an', 0.08333333333333333), ('an interdisciplinary branch', 0.08333333333333333), ('interdisciplinary branch of', 0.08333333333333333), ('branch of linguistics', 0.08333333333333333), ('linguistics , combining', 0.08333333333333333), (', combining knowledge', 0.08333333333333333), ('combining knowledge and', 0.08333333333333333), ('knowledge and research', 0.08333333333333333), ('and research from', 0.08333333333333333), ('research from both', 0.08333333333333333), ('from both psychology', 0.08333333333333333), ('both psychology and', 0.08333333333333333), ('psychology and linguistics', 0.08333333333333333), ('and linguistics .', 0.08333333333333333), ('linguistics . [', 0.08333333333333333), ('. [ 44', 0.08333333333333333), ('[ 44 ]', 0.08333333333333333), ('44 ] especially', 0.08333333333333333), ('] especially during', 0.08333333333333333), ('especially during the', 0.08333333333333333), ('during the age', 0.08333333333333333), ('the age of', 0.08333333333333333), ('age of symbolic', 0.08333333333333333), ('symbolic nlp ,', 0.08333333333333333), ('nlp , the', 0.08333333333333333), (', the area', 0.08333333333333333), ('the area of', 0.08333333333333333), ('area of computational', 0.08333333333333333), ('of computational linguistics', 0.08333333333333333), ('computational linguistics maintained', 0.08333333333333333), ('linguistics maintained strong', 0.08333333333333333), ('maintained strong ties', 0.08333333333333333), ('strong ties with', 0.08333333333333333), ('ties with cognitive', 0.16666666666666666), ('with cognitive studies', 0.08333333333333333), ('cognitive studies .', 0.08333333333333333), ('studies . as', 0.08333333333333333), ('. as an', 0.08333333333333333), ('as an example', 0.08333333333333333), ('an example ,', 0.08333333333333333), ('example , george', 0.08333333333333333), (', george lakoff', 0.08333333333333333), ('george lakoff offers', 0.08333333333333333), ('lakoff offers a', 0.08333333333333333), ('offers a methodology', 0.08333333333333333), ('a methodology to', 0.08333333333333333), ('methodology to build', 0.08333333333333333), ('to build natural', 0.08333333333333333), ('build natural language', 0.08333333333333333), ('nlp ) algorithms', 0.08333333333333333), (') algorithms through', 0.08333333333333333), ('algorithms through the', 0.08333333333333333), ('through the perspective', 0.08333333333333333), ('the perspective of', 0.08333333333333333), ('perspective of cognitive', 0.08333333333333333), ('of cognitive science', 0.08333333333333333), ('cognitive science ,', 0.08333333333333333), ('science , along', 0.08333333333333333), (', along with', 0.08333333333333333), ('along with the', 0.08333333333333333), ('with the findings', 0.08333333333333333), ('the findings of', 0.08333333333333333), ('findings of cognitive', 0.08333333333333333), ('of cognitive linguistics', 0.08333333333333333), ('cognitive linguistics ,', 0.08333333333333333), ('linguistics , [', 0.08333333333333333), (', [ 45', 0.08333333333333333), ('[ 45 ]', 0.08333333333333333), ('45 ] with', 0.08333333333333333), ('] with two', 0.08333333333333333), ('with two defining', 0.08333333333333333), ('two defining aspects', 0.08333333333333333), ('defining aspects :', 0.08333333333333333), ('aspects : ties', 0.08333333333333333), (': ties with', 0.08333333333333333), ('with cognitive linguistics', 0.08333333333333333), ('cognitive linguistics are', 0.08333333333333333), ('linguistics are part', 0.08333333333333333), ('are part of', 0.08333333333333333), ('part of the', 0.08333333333333333), ('of the historical', 0.08333333333333333), ('the historical heritage', 0.08333333333333333), ('historical heritage of', 0.08333333333333333), ('heritage of nlp', 0.08333333333333333), ('of nlp ,', 0.08333333333333333), ('nlp , but', 0.08333333333333333), (', but they', 0.08333333333333333), ('but they have', 0.08333333333333333), ('they have been', 0.08333333333333333), ('have been less', 0.08333333333333333), ('been less frequently', 0.08333333333333333), ('less frequently addressed', 0.08333333333333333), ('frequently addressed since', 0.08333333333333333), ('addressed since the', 0.08333333333333333), ('since the statistical', 0.08333333333333333), ('the statistical turn', 0.08333333333333333), ('statistical turn during', 0.08333333333333333), ('turn during the', 0.08333333333333333), ('during the 1990s', 0.08333333333333333), ('the 1990s .', 0.08333333333333333), ('1990s . nevertheless', 0.08333333333333333), ('. nevertheless ,', 0.08333333333333333), ('nevertheless , approaches', 0.08333333333333333), (', approaches to', 0.08333333333333333), ('approaches to develop', 0.08333333333333333), ('to develop cognitive', 0.08333333333333333), ('develop cognitive models', 0.08333333333333333), ('cognitive models towards', 0.08333333333333333), ('models towards technically', 0.08333333333333333), ('towards technically operationalizable', 0.08333333333333333), ('technically operationalizable frameworks', 0.08333333333333333), ('operationalizable frameworks have', 0.08333333333333333), ('frameworks have been', 0.08333333333333333), ('have been pursued', 0.08333333333333333), ('been pursued in', 0.08333333333333333), ('pursued in the', 0.08333333333333333), ('in the context', 0.08333333333333333), ('the context of', 0.08333333333333333), ('context of various', 0.08333333333333333), ('of various frameworks', 0.08333333333333333), ('various frameworks ,', 0.08333333333333333), ('frameworks , e.g.', 0.08333333333333333), ('e.g. , of', 0.08333333333333333), (', of cognitive', 0.08333333333333333), ('of cognitive grammar', 0.08333333333333333), ('cognitive grammar ,', 0.08333333333333333), ('grammar , [', 0.25), (', [ 47', 0.08333333333333333), ('[ 47 ]', 0.08333333333333333), ('47 ] functional', 0.08333333333333333), ('] functional grammar', 0.08333333333333333), ('functional grammar ,', 0.08333333333333333), (', [ 48', 0.08333333333333333), ('[ 48 ]', 0.08333333333333333), ('48 ] construction', 0.08333333333333333), ('] construction grammar', 0.08333333333333333), ('construction grammar ,', 0.08333333333333333), (', [ 49', 0.08333333333333333), ('[ 49 ]', 0.08333333333333333), ('49 ] computational', 0.08333333333333333), ('] computational psycholinguistics', 0.08333333333333333), ('computational psycholinguistics and', 0.08333333333333333), ('psycholinguistics and cognitive', 0.08333333333333333), ('and cognitive neuroscience', 0.08333333333333333), ('cognitive neuroscience (', 0.08333333333333333), ('neuroscience ( e.g.', 0.08333333333333333), ('e.g. , act-r', 0.08333333333333333), (', act-r )', 0.08333333333333333), ('act-r ) ,', 0.08333333333333333), (') , however', 0.08333333333333333), ('however , with', 0.08333333333333333), (', with limited', 0.08333333333333333), ('with limited uptake', 0.08333333333333333), ('limited uptake in', 0.08333333333333333), ('uptake in mainstream', 0.08333333333333333), ('in mainstream nlp', 0.08333333333333333), ('mainstream nlp (', 0.08333333333333333), ('nlp ( as', 0.08333333333333333), ('( as measured', 0.08333333333333333), ('as measured by', 0.08333333333333333), ('measured by presence', 0.08333333333333333), ('by presence on', 0.08333333333333333), ('presence on major', 0.08333333333333333), ('on major conferences', 0.08333333333333333), ('major conferences [', 0.08333333333333333), ('conferences [ 50', 0.08333333333333333), ('[ 50 ]', 0.08333333333333333), ('50 ] of', 0.08333333333333333), ('] of the', 0.08333333333333333), ('of the acl', 0.08333333333333333), ('the acl )', 0.08333333333333333), ('acl ) .', 0.08333333333333333), (') . more', 0.08333333333333333), ('. more recently', 0.08333333333333333), ('more recently ,', 0.08333333333333333), ('recently , ideas', 0.08333333333333333), (', ideas of', 0.16666666666666666), ('ideas of cognitive', 0.16666666666666666), ('of cognitive nlp', 0.16666666666666666), ('cognitive nlp have', 0.08333333333333333), ('nlp have been', 0.08333333333333333), ('have been revived', 0.08333333333333333), ('been revived as', 0.08333333333333333), ('revived as an', 0.08333333333333333), ('as an approach', 0.08333333333333333), ('an approach to', 0.08333333333333333), ('approach to achieve', 0.08333333333333333), ('to achieve explainability', 0.08333333333333333), ('achieve explainability ,', 0.08333333333333333), ('explainability , e.g.', 0.08333333333333333), ('e.g. , under', 0.08333333333333333), (', under the', 0.08333333333333333), ('under the notion', 0.08333333333333333), ('the notion of', 0.08333333333333333), ('notion of ``', 0.08333333333333333), ('of `` cognitive', 0.08333333333333333), ('`` cognitive ai', 0.08333333333333333), (\"cognitive ai ''\", 0.08333333333333333), (\"ai '' .\", 0.08333333333333333), (\"'' . [\", 0.08333333333333333), ('. [ 51', 0.08333333333333333), ('[ 51 ]', 0.08333333333333333), ('51 ] likewise', 0.08333333333333333), ('] likewise ,', 0.08333333333333333), ('likewise , ideas', 0.08333333333333333), ('cognitive nlp are', 0.08333333333333333), ('nlp are inherent', 0.08333333333333333), ('are inherent to', 0.08333333333333333), ('inherent to neural', 0.08333333333333333), ('to neural models', 0.08333333333333333), ('neural models multimodal', 0.08333333333333333), ('models multimodal nlp', 0.08333333333333333), ('multimodal nlp (', 0.08333333333333333), ('nlp ( although', 0.08333333333333333), ('( although rarely', 0.08333333333333333), ('although rarely made', 0.08333333333333333), ('rarely made explicit', 0.08333333333333333), ('made explicit )', 0.08333333333333333), ('explicit ) .', 0.08333333333333333), (') . [', 0.08333333333333333), ('. [ 52', 0.08333333333333333), ('[ 52 ]', 0.08333333333333333)])\n"
     ]
    }
   ],
   "source": [
    "# 2.2 b \n",
    "\n",
    "n_grams = 3\n",
    "\n",
    "ngram_freq = FreqDist(gen_ngrams(content, n_grams))\n",
    "sent_score = {}\n",
    "maximum_cnt = ngram_freq.most_common(1)[0][1]\n",
    "for each_word in ngram_freq.keys():\n",
    "    ngram_freq[each_word] = ngram_freq[each_word] / maximum_cnt\n",
    "        \n",
    "        \n",
    "print(ngrams_freq_res.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a66f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 c - Calculating the senetence scores\n",
    "def calc_sent_scores_ngrams(sent_tokens, ngram_freq, n_grams):\n",
    "    \n",
    "    sent_score = {}\n",
    "    maximum_cnt = ngram_freq.most_common(1)[0][1]\n",
    "    for each_word in ngram_freq.keys():\n",
    "        ngram_freq[each_word] = ngram_freq[each_word] / maximum_cnt\n",
    "    \n",
    "    for eachsentence in sent_tokens:\n",
    "        sum = 0\n",
    "        sent_n_grams = gen_ngrams(eachsentence.lower(), n_grams)\n",
    "        for each_sent_ngram in sent_n_grams:\n",
    "            sum = sum + ngram_freq[each_sent_ngram]\n",
    "            sent_score[eachsentence] = sum\n",
    "    \n",
    "    # ranked_sent = dict(sorted(sent_score.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    return sent_score        \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "n_grams = 3\n",
    "ngram_freq = FreqDist(gen_ngrams(content, n_grams))\n",
    "sent_score = calc_sent_scores_ngrams(my_sentences, ngram_freq, n_grams)\n",
    "sent_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 d\n",
    "\n",
    "from heapq import nlargest\n",
    "def n_gram_summary_based_on_sent_count(n_grams, sent_count):\n",
    "    ngrams_frequency = FreqDist(gen_ngrams(content, n_grams))\n",
    "    sent_scores = calc_sent_scores_ngrams(my_sentences, ngrams_frequency, n_grams)\n",
    "    sent_summary = nlargest(sent_count, sent_scores, key=sent_scores.get)\n",
    "    final_res = \" \".join(sent_summary)\n",
    "    return final_res\n",
    "    \n",
    "print(n_gram_summary_based_on_sent_count(3,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a5af3",
   "metadata": {},
   "source": [
    "## Task 3 - Comparison\n",
    "\n",
    "In the first task, we divided the sentences word by word and found out which sentence had the highest score based on their weighted frequencies. \n",
    "\n",
    "In the second task, we split the sentences into two or more words and then found out which one occurred the most based on their frequencies. \n",
    "\n",
    "The second task produced more meaningful and trustworthy results as we have the chance to consider phrases instead of just using a single word. For example, the phrase 'natural processing language' has a higher probability of appearing together as it is a more coherent and also commonly used phrase. Whereas the individual words - natural, processing and language would mean differently in different contexts. \n",
    "\n",
    "\n",
    "#### 115 words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
